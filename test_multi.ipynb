{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tmp = pd.read_csv(\"data/run2/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0003187562499999907, 0.0011545166666666433, 0.07146388124999997)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[\"Signs\"].mean(), tmp[\"Lights\"].mean(), tmp[\"Vehicles\"].mean()\n",
    "#[0.602, 1.087, 1.203]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9300697916666667,\n",
       " 0.06845729166666659,\n",
       " 1.875e-05,\n",
       " 0.00047187499999995,\n",
       " 0.0699302083333333)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[\"Unlabeled\"].median(),tmp[\"Vehicles\"].median(), tmp[\"Signs\"].median(),tmp[\"Lights\"].median(),  tmp[\"All\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0239707051482794, 21251.999999999953, 234.82872928178816)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signs = tmp[\"Signs\"].median()\n",
    "lights = tmp[\"Lights\"].median()\n",
    "vehicles = tmp[\"Vehicles\"].median()\n",
    "test = tmp[\"Signs\"] + tmp[\"Lights\"] + tmp[\"Vehicles\"]\n",
    "a = test.median()\n",
    "a/vehicles, a/signs, a/lights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06972812499999995"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tmp[\"Signs\"] + tmp[\"Lights\"] + tmp[\"Vehicles\"]\n",
    "test.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 37)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_frq = [0.382900, 0.452448, 0.637584, 0.377464, 0.585595,\n",
    "           0.479574, 0.781544, 0.982534, 1.017466, 0.624581,\n",
    "           2.589096, 0.980794, 0.920340, 0.667984, 1.172291,\n",
    "           0.862240, 0.921714, 2.154782, 1.187832, 1.178115,\n",
    "           1.848545, 1.428922, 2.849658, 0.771605, 1.656668,\n",
    "           4.483506, 2.209922, 1.120280, 2.790182, 0.706519,\n",
    "           3.994768, 2.220004, 0.972934, 1.481525, 5.342475,\n",
    "           0.750738, 4.040773]\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "label_colours = [(0, 0, 0),\n",
    "                 # 0=background\n",
    "                 (148, 65, 137), (255, 116, 69), (86, 156, 137),\n",
    "                 (202, 179, 158), (155, 99, 235), (161, 107, 108),\n",
    "                 (133, 160, 103), (76, 152, 126), (84, 62, 35),\n",
    "                 (44, 80, 130), (31, 184, 157), (101, 144, 77),\n",
    "                 (23, 197, 62), (141, 168, 145), (142, 151, 136),\n",
    "                 (115, 201, 77), (100, 216, 255), (57, 156, 36),\n",
    "                 (88, 108, 129), (105, 129, 112), (42, 137, 126),\n",
    "                 (155, 108, 249), (166, 148, 143), (81, 91, 87),\n",
    "                 (100, 124, 51), (73, 131, 121), (157, 210, 220),\n",
    "                 (134, 181, 60), (221, 223, 147), (123, 108, 131),\n",
    "                 (161, 66, 179), (163, 221, 160), (31, 146, 98),\n",
    "                 (99, 121, 30), (49, 89, 240), (116, 108, 9),\n",
    "                 (161, 176, 169), (80, 29, 135), (177, 105, 197),\n",
    "                 (139, 110, 246)]\n",
    "len(label_colours), len(med_frq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import carla\n",
    "import random\n",
    "import queue\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "client = carla.Client('localhost', 2000)\n",
    "world  = client.get_world()\n",
    "bp_lib = world.get_blueprint_library()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spawn_points = world.get_map().get_spawn_points()\n",
    "vehicle_bp =bp_lib.find('vehicle.lincoln.mkz_2020')\n",
    "vehicle = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points))\n",
    "\n",
    "# for i in range(50):\n",
    "#     vehicle_bp = random.choice(bp_lib.filter('vehicle'))\n",
    "#     npc = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points))\n",
    "#     if npc:\n",
    "#         npc.set_autopilot(True)\n",
    "\n",
    "# spawn camera\n",
    "camera_r = bp_lib.find('sensor.camera.rgb')\n",
    "camera_init_trans = carla.Transform(carla.Location(z=2))\n",
    "camera_rgb = world.spawn_actor(camera_r, camera_init_trans, attach_to=vehicle)\n",
    "\n",
    "camera_d = bp_lib.find('sensor.camera.depth')\n",
    "camera_init_trans = carla.Transform(carla.Location(z=2))\n",
    "camera_depth = world.spawn_actor(camera_d, camera_init_trans, attach_to=vehicle)\n",
    "\n",
    "camera_s = bp_lib.find('sensor.camera.semantic_segmentation')\n",
    "camera_init_trans = carla.Transform(carla.Location(z=2))\n",
    "camera_semantic = world.spawn_actor(camera_s, camera_init_trans, attach_to=vehicle)\n",
    "\n",
    "vehicle.set_autopilot(True)\n",
    "\n",
    "# Set up the simulator in synchronous mode\n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = True # Enables synchronous mode\n",
    "settings.fixed_delta_seconds = 5\n",
    "world.apply_settings(settings)\n",
    "\n",
    "# Create a queue to store and retrieve the sensor data\n",
    "rgb_queue = queue.Queue()\n",
    "camera_rgb.listen(rgb_queue.put)\n",
    "depth_queue = queue.Queue()\n",
    "camera_depth.listen(depth_queue.put)\n",
    "semantic_queue = queue.Queue()\n",
    "camera_semantic.listen(semantic_queue.put)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spectator',\n",
       " 'traffic.speed_limit.30',\n",
       " 'traffic.speed_limit.60',\n",
       " 'static.prop.mesh',\n",
       " 'traffic.speed_limit.90',\n",
       " 'traffic.traffic_light']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import carla\n",
    "import random\n",
    "import queue\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "client = carla.Client('localhost', 2000)\n",
    "world  = client.get_world()\n",
    "test = []\n",
    "for i in world.get_actors():\n",
    "    test.append(i.type_id)\n",
    "list(set(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'traffic.traffic_light',\n",
    "'vehicle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "world.tick()\n",
    "actor_list = []\n",
    "for i in world.get_actors().filter('*vehicle*'):\n",
    "    actor_list.append(i)\n",
    "for i in world.get_actors().filter('*traffic*'):\n",
    "    actor_list.append(i)\n",
    "vehicles = 0\n",
    "trafficsigns = 0\n",
    "trafficlight = 0\n",
    "for curr in actor_list:\n",
    "    if curr.id != vehicle.id:\n",
    "        bb = curr.bounding_box\n",
    "        dist = curr.get_transform().location.distance(vehicle.get_transform().location)\n",
    "        print(dist)\n",
    "        if dist < 50:\n",
    "            print(\"test\")\n",
    "            forward_vec = vehicle.get_transform().get_forward_vector()\n",
    "            ray = curr.get_transform().location - vehicle.get_transform().location\n",
    "\n",
    "            if forward_vec.dot(ray) > 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800,\n",
       " 600,\n",
       " <bound method as_float of <carla.libcarla.ActorAttribute object at 0x0000024C52E85CF0>>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_w = camera_r.get_attribute(\"image_size_x\").as_int()\n",
    "image_h = camera_r.get_attribute(\"image_size_y\").as_int()\n",
    "fov = camera_r.get_attribute(\"fov\").as_float\n",
    "image_w, image_h, fov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800,\n",
       " 600,\n",
       " <bound method as_float of <carla.libcarla.ActorAttribute object at 0x0000024C52E85DB0>>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_w = camera_d.get_attribute(\"image_size_x\").as_int()\n",
    "image_h = camera_d.get_attribute(\"image_size_y\").as_int()\n",
    "fov = camera_d.get_attribute(\"fov\").as_float\n",
    "image_w, image_h, fov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world.tick()\n",
    "image = rgb_queue.get()\n",
    "img_rgb = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "cv2.imwrite(\"out/test_rgb.png\", img_rgb)\n",
    "\n",
    "image = depth_queue.get()\n",
    "image.convert(carla.ColorConverter.LogarithmicDepth)\n",
    "img_depth = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "cv2.imwrite(\"out/test_depth.png\", img_depth)\n",
    "\n",
    "image = semantic_queue.get()\n",
    "image.convert(carla.ColorConverter.CityScapesPalette)\n",
    "img_semantic = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "cv2.imwrite(\"out/test_semantic.png\", img_semantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "world.tick()\n",
    "imaged = depth_queue.get()\n",
    "imager = rgb_queue.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 800)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.reshape(np.copy(imaged.raw_data), (imaged.height, imaged.width, 4))\n",
    "normalized_depth = np.dot(array[:, :, :3], [65536.0, 256.0, 1.0])\n",
    "normalized_depth /= 16777215.0  # (256.0 * 256.0 * 256.0 - 1.0)\n",
    "normalized_depth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 800, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_semantic = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "img_semantic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13, 13, 13, ...,  9,  9,  9],\n",
       "       [13, 13, 13, ...,  9,  9,  9],\n",
       "       [13, 13, 13, ...,  9,  9,  9],\n",
       "       ...,\n",
       "       [ 7,  7,  7, ...,  8,  8,  8],\n",
       "       [ 7,  7,  7, ...,  8,  8,  8],\n",
       "       [ 7,  7,  7, ...,  8,  8,  8]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_semantic[:,:,2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}