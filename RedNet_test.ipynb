{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "from lib import RedNet_model\n",
    "from lib import RedNet_data_test as RedNet_data\n",
    "from lib.utils import utils\n",
    "from lib.utils.utils import save_ckpt\n",
    "from lib.utils.utils import print_log\n",
    "from lib.utils.utils import load_ckpt\n",
    "import imageio\n",
    "from torch.optim.lr_scheduler import LambdaLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "checkpoint_path = \"lib/models/model1/ckpt_epoch_410.00.pth\"\n",
    "image_path = \"out/image_0.png\"\n",
    "depth_path = \"out/image_0.npy\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "image_w = 640\n",
    "image_h = 480\n",
    "weight_decay = 1e-4\n",
    "momentum = 0.9\n",
    "lr = 2e-3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'lib/models/model1/ckpt_epoch_410.00.pth'\n",
      "=> loaded checkpoint 'lib/models/model1/ckpt_epoch_410.00.pth' (epoch 410.0)\n"
     ]
    }
   ],
   "source": [
    "transform=transforms.Compose([RedNet_data.scaleNorm(),\n",
    "                              RedNet_data.RandomHSV((0.9, 1.1),\n",
    "                                                    (0.9, 1.1),\n",
    "                                                    (25, 25)),\n",
    "                              RedNet_data.ToTensor(),\n",
    "                              RedNet_data.Normalize()])\n",
    "model = RedNet_model.RedNet(pretrained=False)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr,\n",
    "                            momentum=momentum, weight_decay=weight_decay)\n",
    "global_step, start_epoch = load_ckpt(model, optimizer, checkpoint_path, device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 480, 640]) torch.Size([1, 1, 480, 640])\n"
     ]
    },
    {
     "data": {
      "text/plain": "(tensor([[[[ 1.0233e+01,  1.5092e+01,  1.3619e+01,  ...,  1.4025e+01,\n             4.1557e+00,  9.3533e+00],\n           [ 6.2937e+00,  1.0560e+01,  8.9087e+00,  ...,  9.5228e+00,\n             3.5957e+00,  5.8160e+00],\n           [ 5.0701e+00,  6.0989e+00,  1.1211e+01,  ...,  8.4574e+00,\n             1.5749e-01,  4.5789e+00],\n           ...,\n           [ 1.7223e+00,  1.6987e+00,  3.8527e+00,  ...,  1.9944e+00,\n             1.5214e+00,  2.5575e+00],\n           [ 2.5427e+00,  4.8746e+00,  2.7340e+00,  ...,  3.4493e+00,\n             2.1133e+00,  6.8259e+00],\n           [ 1.1783e+00,  3.3891e+00,  1.1062e+00,  ...,  3.0241e+00,\n             2.3961e+00,  4.3854e+00]],\n \n          [[-9.1069e+00, -4.6165e+00, -4.5849e+00,  ..., -5.0374e+00,\n            -3.8168e+00, -2.4436e+00],\n           [-9.0016e+00, -5.9510e+00, -4.5201e+00,  ..., -3.3469e+00,\n            -4.5130e+00,  1.8411e-01],\n           [-1.6714e+00,  1.2031e+00, -4.6064e+00,  ..., -5.9614e+00,\n            -4.5452e+00, -1.7874e+00],\n           ...,\n           [-3.0835e+00, -2.7420e+00, -3.8777e+00,  ..., -1.6137e+00,\n            -2.9736e+00, -2.7435e+00],\n           [-1.3922e+00,  1.1125e+00, -1.2168e-01,  ..., -6.8252e-01,\n            -1.9757e+00,  1.9559e+00],\n           [-2.3494e+00,  4.3555e-01, -2.8877e+00,  ..., -5.5304e-02,\n            -1.5168e-02,  4.1472e-01]],\n \n          [[-8.4481e+00, -3.5095e+00, -6.0881e+00,  ..., -5.3040e+00,\n            -7.3179e+00, -6.3539e+00],\n           [-7.8603e+00, -6.0489e+00, -4.8770e+00,  ...,  2.0839e+00,\n            -2.4468e+00,  1.1400e-02],\n           [-3.5893e+00, -1.7298e-01, -9.0716e-01,  ...,  1.6510e-01,\n            -6.9856e-01,  3.8150e+00],\n           ...,\n           [-3.9448e+00, -3.5058e+00, -5.4651e+00,  ..., -2.4983e+00,\n            -3.6220e+00, -1.6405e+00],\n           [-3.0873e+00,  3.7587e-01, -2.4992e+00,  ..., -2.4455e+00,\n            -7.3782e+00, -1.1293e+00],\n           [-4.6485e+00, -2.5350e+00, -6.4026e+00,  ..., -2.8321e+00,\n            -5.3755e+00, -2.2970e+00]]]], device='cuda:0',\n        grad_fn=<ConvolutionBackward0>),\n tensor([[[[ -2.6537,   9.4562,  -0.4110,  ...,   6.9965,  -0.1405,   3.5960],\n           [  3.1381,  -0.0998,  10.2602,  ...,   2.3444,   2.4021,   0.4369],\n           [ -2.5492,   9.2639,   3.2707,  ...,  10.1835,   0.4037,   4.0993],\n           ...,\n           [  3.0792,   3.0010,   4.5884,  ...,   3.9236,   1.5396,   2.0734],\n           [  1.2029,   1.7551,   3.9959,  ...,   1.5314,   1.0486,   0.4460],\n           [  1.5737,   2.6536,   3.2829,  ...,   3.7171,   2.4287,   2.7477]],\n \n          [[ -9.5881,  -4.3113, -10.9473,  ...,  -4.2041,  -4.8385,  -1.8431],\n           [ -1.8240, -11.7798,   1.4853,  ...,  -8.5346,  -1.5868,  -1.9798],\n           [-10.6297,  -4.9059, -12.2881,  ...,  -4.6262,  -5.4119,  -1.4925],\n           ...,\n           [ -1.6715,  -4.2894,  -3.3422,  ...,  -4.6089,  -3.6040,  -3.7033],\n           [ -2.9626,  -3.0651,  -3.3950,  ...,  -4.1053,  -3.5946,  -3.3746],\n           [ -1.0916,  -1.1786,  -1.6878,  ...,  -2.1471,  -1.9281,  -0.1851]],\n \n          [[ -4.9468,  -0.6581,  -6.4822,  ...,  -1.4021,  -2.5938,  -1.5117],\n           [  1.0716, -14.4244,   1.5811,  ..., -10.0713,  -1.3397,  -6.6756],\n           [ -5.4308,  -1.1205,  -9.5440,  ...,  -2.4602,  -2.6823,  -1.6724],\n           ...,\n           [ -3.6060,  -5.0922,  -4.7909,  ...,  -4.5919,  -3.8174,  -3.9032],\n           [ -3.6941,  -3.6393,  -4.6763,  ...,  -3.9558,  -3.1787,  -3.8689],\n           [ -3.8801,  -4.4646,  -5.3724,  ...,  -4.5149,  -4.7755,  -3.8168]]]],\n        device='cuda:0', grad_fn=<ConvolutionBackward0>),\n tensor([[[[  3.7576,   3.2558,   5.5241,  ...,   4.8728,   3.9448,   0.3474],\n           [  4.5058,   0.9082,   8.6820,  ...,   3.2856,   4.2734,   1.7724],\n           [  4.8241,   5.9347,   7.8168,  ...,   8.5578,   4.5139,   2.1303],\n           ...,\n           [  4.7060,   4.9283,   6.0142,  ...,   4.3617,   4.6730,   3.2884],\n           [  5.4391,   3.2897,   6.2710,  ...,   2.8527,   4.8600,   1.4624],\n           [  3.6824,   3.2070,   4.4066,  ...,   3.6816,   3.9326,   2.1972]],\n \n          [[ -3.2001,  -5.9187,  -4.5544,  ...,  -9.9508,  -3.8538,  -6.6980],\n           [ -1.8568, -17.6298,  -4.4707,  ..., -21.6906,  -4.0021, -11.3134],\n           [ -2.5611,  -9.0151,  -6.1472,  ..., -12.5298,  -4.2400,  -8.0561],\n           ...,\n           [ -4.4004,  -5.6659,  -5.9718,  ...,  -5.5720,  -4.9794,  -4.9646],\n           [ -2.4842,  -5.6963,  -3.6958,  ...,  -5.1284,  -2.8871,  -4.5840],\n           [ -2.3032,  -3.0407,  -3.4008,  ...,  -4.1579,  -3.5635,  -2.7251]],\n \n          [[ -3.3995, -29.7739,  -6.8665,  ..., -26.4428,  -4.0051, -14.0820],\n           [ -6.0703, -20.6456, -10.4951,  ..., -18.6781,  -3.7999,  -9.3318],\n           [ -8.2148, -37.1977, -10.7689,  ..., -25.8808,  -3.6404, -12.1776],\n           ...,\n           [ -6.8341,  -7.5569,  -8.0262,  ...,  -6.2947,  -5.3348,  -4.4518],\n           [ -5.9644,  -8.9082,  -6.1803,  ...,  -6.1167,  -4.0756,  -4.7342],\n           [ -8.2078,  -9.3132,  -7.4131,  ...,  -6.5379,  -7.7459,  -6.3279]]]],\n        device='cuda:0', grad_fn=<ConvolutionBackward0>),\n tensor([[[[ 16.5983,  17.6187,  39.9194,  ...,  24.1237,  17.6963,  13.3720],\n           [ 13.6490,  27.4902,  24.5570,  ...,  32.1688,  11.8523,  12.3860],\n           [ 11.5378,  13.3022,  27.1125,  ...,  20.3096,  12.1370,  10.0802],\n           ...,\n           [  6.1223,   8.8007,  10.0300,  ...,   9.3680,   7.6329,   5.5439],\n           [  4.8424,   9.1922,   7.7910,  ...,  10.1192,   6.5139,   6.4456],\n           [  3.8304,   6.0633,   8.4298,  ...,   7.4789,   5.8476,   4.7303]],\n \n          [[  6.9834,   6.3672,  -1.8927,  ...,   4.0243,  -0.0581,   1.8201],\n           [  6.7626,  11.1763,   7.9042,  ...,   5.9689,   0.4923,   4.0507],\n           [  2.6471,   2.9076,  -5.2999,  ...,  -0.1199,  -2.1357,  -0.5730],\n           ...,\n           [ -0.1804,   0.0765,  -0.3087,  ...,  -0.9416,  -1.2639,  -0.6682],\n           [ -0.4576,   0.4174,  -1.6151,  ...,  -1.4034,  -1.3158,   0.6158],\n           [  0.7951,   2.0687,   1.4257,  ...,   0.3026,   0.6186,   0.3074]],\n \n          [[  8.1382,   6.3885,  21.7029,  ...,  10.4484,   7.9284,   5.2396],\n           [  3.2019, -12.3052,  10.7204,  ..., -10.7234,   4.3058,  -5.1595],\n           [  4.9566,   3.7678,  16.7439,  ...,   5.0585,   2.5966,   1.1761],\n           ...,\n           [ -3.5838,  -7.3156,  -5.3007,  ...,  -7.4804,  -3.1513,  -4.4292],\n           [ -3.4113,  -2.1589,  -5.2606,  ...,  -2.9702,  -3.9078,  -0.4030],\n           [ -4.8252,  -6.4173,  -6.0500,  ...,  -6.3754,  -4.9708,  -4.3361]]]],\n        device='cuda:0', grad_fn=<ConvolutionBackward0>),\n tensor([[[[ 9.8722e+00,  1.5091e+01,  1.0208e+01,  ...,  3.5389e+01,\n             1.1418e+01,  1.8182e+01],\n           [ 7.6276e+00, -6.3973e+00,  1.4814e+01,  ..., -3.1121e+01,\n             1.2715e+01, -2.2812e+00],\n           [ 7.4476e+00,  8.5145e+00,  1.0203e+01,  ...,  1.0684e+01,\n             8.7189e+00,  7.2375e+00],\n           ...,\n           [ 7.4699e+00,  1.0381e+01,  9.1473e+00,  ...,  9.4966e+00,\n             8.4013e+00,  1.1041e+01],\n           [ 8.9896e+00,  1.2392e+01,  9.4060e+00,  ...,  1.2389e+01,\n             8.8680e+00,  9.4186e+00],\n           [ 7.4150e+00,  1.3962e+01,  7.7871e+00,  ...,  1.3406e+01,\n             7.3016e+00,  1.2315e+01]],\n \n          [[-2.6776e-01, -1.0730e+01, -3.7614e+00,  ..., -4.9857e+01,\n            -3.0013e+00, -2.0385e+01],\n           [-5.5758e-01, -1.9055e+01,  1.2432e+00,  ..., -6.2429e+01,\n            -3.6720e+00, -1.9998e+01],\n           [-4.5082e-01, -2.3645e-02,  6.1215e-01,  ..., -1.1454e-02,\n             3.8987e-01,  4.3327e-01],\n           ...,\n           [-4.8684e+00, -3.5984e+00, -5.1534e+00,  ..., -4.6075e+00,\n            -4.8906e+00, -8.1934e-01],\n           [-3.5727e+00, -2.9665e+00, -4.3584e+00,  ..., -2.1805e+00,\n            -3.2609e+00, -1.8861e+00],\n           [-8.0418e+00, -2.6194e+00, -8.2713e+00,  ..., -3.6097e+00,\n            -8.5320e+00, -1.5179e+00]],\n \n          [[-6.7366e+00, -1.7095e+01, -8.3014e+00,  ..., -3.7339e+01,\n            -7.3637e+00, -1.7404e+01],\n           [-1.0644e+01, -2.9421e+01, -1.0672e+01,  ..., -4.9541e+01,\n            -8.1765e+00, -1.3800e+01],\n           [-6.1692e+00, -5.8193e+00, -7.3704e+00,  ..., -8.8738e+00,\n            -7.6803e+00, -5.8213e+00],\n           ...,\n           [-6.0053e+00, -8.8885e+00, -4.5805e+00,  ..., -7.4699e+00,\n            -6.6584e+00, -5.0907e+00],\n           [-2.1579e+00, -4.7274e+00, -1.5299e+00,  ..., -6.4960e+00,\n            -4.5306e+00, -3.9804e+00],\n           [-6.5004e+00, -4.6452e+00, -5.9405e+00,  ..., -5.5778e+00,\n            -7.1864e+00, -3.8170e+00]]]], device='cuda:0',\n        grad_fn=<ConvolutionBackward0>))"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_raw = np.load(depth_path)\n",
    "image_raw = imageio.v2.imread(image_path, pilmode='RGB')\n",
    "sample = {'image':image_raw, 'depth': depth_raw}\n",
    "sample = transform(sample)\n",
    "image = sample['image'].reshape((1,3,480,640))\n",
    "depth = sample['depth'].reshape((1,1,480,640))\n",
    "image = image.to(device)\n",
    "depth = depth.to(device)\n",
    "print(image.shape, depth.shape)\n",
    "pred_scales = model(image, depth, False)\n",
    "pred_scales"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "(480, 640)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_colours = [[0, 0, 0],[148, 65, 137], [255, 116, 69], [86, 156, 137]]\n",
    "colors = torch.max(pred_scales[0][:3], 1)[1] + 1\n",
    "colors = colors.cpu().detach().numpy()\n",
    "colors = colors.reshape(colors.shape[1:])\n",
    "colors.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "(480, 640, 3)"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "image_raw = imageio.v2.imread(image_path, pilmode='RGB')\n",
    "image_raw = cv2.resize(image_raw,(640,480))\n",
    "image_raw.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 2, 3], dtype=int64)"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(colors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "(480, 640, 3)"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_raw = imageio.v2.imread(image_path, pilmode='RGB')\n",
    "image_raw = cv2.resize(image_raw,(640,480))\n",
    "new_image = image_raw\n",
    "#colors.reshape(colors.shape[1:])\n",
    "for i in range(480):\n",
    "    for j in range(640):\n",
    "        if colors[i,j] != 1:\n",
    "            new_image[i,j] = label_colours[colors[i,j]]\n",
    "new_image.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "cv2.imwrite(\"out/test_0.png\",new_image)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}